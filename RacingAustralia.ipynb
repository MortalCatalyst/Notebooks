{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is https://www.racingaustralia.horse/FreeFields/Calendar_Results.aspx?State=NSW page details\n",
      "Saturday, 19 June 2021\n",
      "Saturday, 19 June 2021, ROYALZEL \n",
      "{'Rail Position:': '+7m Entire', 'Dual Track Meeting:': 'N', 'Track Type:': 'Turf', 'Track Condition:': 'Heavy 8', 'Weather:': 'Showers', 'Penetrometer:': '5.98', 'Track Information:': 'Chance of possible late showers', 'Results Last Published:': 'Sun 20-Jun-21 1:06AM AEST'}\n"
     ]
    }
   ],
   "source": [
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import re\r\n",
    "\r\n",
    "def getRequest(url):\r\n",
    "    try:\r\n",
    "        return BeautifulSoup(requests.get(url).content, \"html.parser\")        \r\n",
    "    except Exception as e:\r\n",
    "        print(\"The URL failed to return\")\r\n",
    "        print(getattr(e, 'message', repr(e)))\r\n",
    "        \r\n",
    "        \r\n",
    "url = \"https://www.racingaustralia.horse\"\r\n",
    "main_page_url = \"https://www.racingaustralia.horse/home.aspx\"\r\n",
    "\r\n",
    "soup = getRequest(main_page_url)\r\n",
    "\r\n",
    "results = [i['href'] for i in soup.select('[href*=Calendar_Results]')]\r\n",
    "\r\n",
    "stateResults = []\r\n",
    "\r\n",
    "for item in results:\r\n",
    "    state = url + item\r\n",
    "    stateResults.append(\"%s\" % state)\r\n",
    "# \r\n",
    "#TODO Review option to use /InteractiveForm/TrackCondition.aspx?State=NSW\r\n",
    "#TODO Put a loop here to loop the states\r\n",
    "interim = stateResults[0]\r\n",
    "\r\n",
    "statePage = requests.get(interim)\r\n",
    "stateSoup = BeautifulSoup(statePage.content, \"html.parser\")\r\n",
    "\r\n",
    "\r\n",
    "print(f\"This is {interim} page details\")\r\n",
    "\r\n",
    "\r\n",
    "gardens = []\r\n",
    "for item in stateSoup.findAll('a'):\r\n",
    "    if item.attrs['href'].endswith('Gardens'):\r\n",
    "        gardens.append(url + item['href'])\r\n",
    "        \r\n",
    "\r\n",
    "resultContent = getRequest(gardens[0])\r\n",
    "\r\n",
    "print(resultContent.find('span').text)\r\n",
    "# print(resultContent)\r\n",
    "\r\n",
    "keys = []\r\n",
    "values = []\r\n",
    "\r\n",
    "r1 = \"https://www.racingaustralia.horse/FreeFields/Results.aspx?Key=2021Jun19,NSW,Rosehill%20Gardens#Race1\"\r\n",
    "test_data = getRequest(r1)\r\n",
    "print(test_data.find('span').text + \", \" + test_data.find(\"td\", {\"class\" : \"horse\"} ).text)\r\n",
    "\r\n",
    "stats = test_data.find('div', {'class': 'race-venue-bottom'})\r\n",
    "for data in stats.findAll('b'):\r\n",
    "    keys.append(data.text)\r\n",
    "\r\n",
    "def find_by_label(soup, label):\r\n",
    "    return soup.find(\"b\", text=re.compile(label)).next_sibling\r\n",
    "\r\n",
    "for key in keys:\r\n",
    "    values.append(find_by_label(stats, key).strip())\r\n",
    "\r\n",
    "track_details = dict(zip(keys, values))\r\n",
    "\r\n",
    "print(track_details)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de2fbdc5ea4bcabd9c94e1b89c75e2f585cef33d261b99650aa271a24d900136"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('WebScraping': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}