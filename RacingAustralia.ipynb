{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saturday, 26 June 2021\n",
      "Saturday, 19 June 2021\n",
      "Saturday, 05 June 2021\n",
      "Saturday, 19 June 2021, ROYALZEL \n",
      "{'Rail Position:': '+7m Entire', 'Dual Track Meeting:': 'N', 'Track Type:': 'Turf', 'Track Condition:': 'Heavy 8', 'Weather:': 'Showers', 'Penetrometer:': '5.98', 'Track Information:': 'Chance of possible late showers', 'Results Last Published:': 'Sun 20-Jun-21 1:06AM AEST'}\n"
     ]
    }
   ],
   "source": [
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import re\r\n",
    "\r\n",
    "def getRequest(url):\r\n",
    "    try:\r\n",
    "        return BeautifulSoup(requests.get(url).content, \"html.parser\")        \r\n",
    "    except Exception as e:\r\n",
    "        print(\"The URL failed to return\")\r\n",
    "        print(getattr(e, 'message', repr(e)))\r\n",
    "       \r\n",
    "\r\n",
    "url = \"https://www.racingaustralia.horse\"\r\n",
    "main_page_url = \"https://www.racingaustralia.horse/home.aspx\"\r\n",
    "\r\n",
    "# results = [i['href'] for i in soup.select('[href*=Calendar_Results]')]\r\n",
    "\r\n",
    "results = [i['href'] for i in getRequest(main_page_url).select('[href*=Calendar_Results]')]\r\n",
    "    \r\n",
    "stateResults = []\r\n",
    "\r\n",
    "for item in results:\r\n",
    "    state = url + item\r\n",
    "    stateResults.append(\"%s\" % state)\r\n",
    "    \r\n",
    "# print(stateResults)\r\n",
    "# # \r\n",
    "#TODO Review option to use /InteractiveForm/TrackCondition.aspx?State=NSW\r\n",
    "#TODO Put a loop here to loop the states\r\n",
    "interim = stateResults[0]\r\n",
    "gardens = []\r\n",
    "\r\n",
    "#TODO determine track names to retrieve URLS (endswith)\r\n",
    "for item in stateResults:\r\n",
    "    for state_url in getRequest(item).findAll('a'):\r\n",
    "        if state_url.attrs['href'].endswith('Gardens'):\r\n",
    "            gardens.append(f\"{url}{state_url['href']}\")\r\n",
    "\r\n",
    "# removes list duplicates\r\n",
    "url_list = list(dict.fromkeys(gardens))\r\n",
    "# Gets Meeting Dates.\r\n",
    "for item in url_list:\r\n",
    "    try:\r\n",
    "        print(getRequest(item).find('span').text)\r\n",
    "    except:\r\n",
    "        print(f\"maybe a bad url {getRequest(item)}\")\r\n",
    "\r\n",
    "keys = []\r\n",
    "values = []\r\n",
    "\r\n",
    "r1 = \"https://www.racingaustralia.horse/FreeFields/Results.aspx?Key=2021Jun19,NSW,Rosehill%20Gardens#Race1\"\r\n",
    "test_data = getRequest(r1)\r\n",
    "print(test_data.find('span').text + \", \" + test_data.find(\"td\", {\"class\" : \"horse\"} ).text)\r\n",
    "\r\n",
    "stats = test_data.find('div', {'class': 'race-venue-bottom'})\r\n",
    "for data in stats.findAll('b'):\r\n",
    "    keys.append(data.text)\r\n",
    "\r\n",
    "def find_by_label(soup, label):\r\n",
    "    return soup.find(\"b\", text=re.compile(label)).next_sibling\r\n",
    "\r\n",
    "for key in keys:\r\n",
    "    values.append(find_by_label(stats, key).strip())\r\n",
    "\r\n",
    "track_details = dict(zip(keys, values))\r\n",
    "\r\n",
    "print(track_details)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de2fbdc5ea4bcabd9c94e1b89c75e2f585cef33d261b99650aa271a24d900136"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('WebScraping': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}